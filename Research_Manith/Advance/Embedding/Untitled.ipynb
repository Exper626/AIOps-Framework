{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a775201e-4fd5-417d-b5ee-c71089222869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.5.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (1.69.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (5.29.3)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: sentence-transformers>=3 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: datasets==2.19.1 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.19.1)\n",
      "Requirement already satisfied: transformers==4.41.2 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.41.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets==2.19.1) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets==2.19.1) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets==2.19.1) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets==2.19.1) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets==2.19.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets==2.19.1) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets==2.19.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets==2.19.1) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets==2.19.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets==2.19.1) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.1) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets==2.19.1) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets==2.19.1) (0.29.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets==2.19.1) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets==2.19.1) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers==4.41.2) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers==4.41.2) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers==4.41.2) (0.5.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers>=3) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers>=3) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers>=3) (1.12.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers>=3) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers>=3) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets==2.19.1) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets==2.19.1) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets==2.19.1) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets==2.19.1) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets==2.19.1) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets==2.19.1) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets==2.19.1) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->datasets==2.19.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->datasets==2.19.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->datasets==2.19.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->datasets==2.19.1) (2024.12.14)\n",
      "Requirement already satisfied: networkx in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=3) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=3) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=3) (75.5.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=3) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=3) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.62.1->datasets==2.19.1) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets==2.19.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets==2.19.1) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets==2.19.1) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers>=3) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers>=3) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.19.1) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ashwinir\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=3) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# Install Pytorch & other libraries\n",
    "!pip install \"torch\" tensorboard\n",
    "\n",
    "# Install Hugging Face libraries\n",
    "!pip install --upgrade \\\n",
    "  \"sentence-transformers>=3\" \\\n",
    "  \"datasets==2.19.1\"  \\\n",
    "  \"transformers==4.41.2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307c11de-cfe4-461d-b857-1488fece5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"\", add_to_git_credential=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f3203a8-7c6a-47af-8582-c2680b29f4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63fe1d2d3534cc7839ceedccd62285a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/882 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6743a4f8a90e41d787c120289e1c0de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9d819ae62343c09123ebfa0cc13cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/7000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95edc88209374c77b3a46bfc5184f46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6a06c581dd4c1298a08624d1b73755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "235216"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset(\"philschmid/finanical-rag-embedding-dataset\", split=\"train\")\n",
    "\n",
    "# rename columns\n",
    "dataset = dataset.rename_column(\"question\", \"anchor\")\n",
    "dataset = dataset.rename_column(\"context\", \"positive\")\n",
    "\n",
    "# Add an id column to the dataset\n",
    "dataset = dataset.add_column(\"id\", range(len(dataset)))\n",
    "\n",
    "# split dataset into a 10% test set\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "# save datasets to disk\n",
    "dataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\")\n",
    "dataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f15b2295-a0bc-40ab-ab1d-9d3248a34a3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\ashwinir\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     InformationRetrievalEvaluator,\n\u001b[0;32m      5\u001b[0m     SequentialEvaluator,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cos_sim\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\__init__.py:14\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     export_dynamic_quantized_onnx_model,\n\u001b[0;32m     11\u001b[0m     export_optimized_onnx_model,\n\u001b[0;32m     12\u001b[0m     export_static_quantized_openvino_model,\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     CrossEncoder,\n\u001b[0;32m     16\u001b[0m     CrossEncoderModelCardData,\n\u001b[0;32m     17\u001b[0m     CrossEncoderTrainer,\n\u001b[0;32m     18\u001b[0m     CrossEncoderTrainingArguments,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainer\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_args\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainingArguments\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoder\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoderTrainer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoderTrainingArguments\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoderModelCardData\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\trainer.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EvalPrediction, PreTrainedTokenizerBase, TrainerCallback\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m transformers_version\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_collator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataCollator\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WandbCallback\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\data\\__init__.py:27\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_collator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     DataCollatorForLanguageModeling,\n\u001b[0;32m     17\u001b[0m     DataCollatorForPermutationLanguageModeling,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     default_data_collator,\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m glue_compute_metrics, xnli_compute_metrics\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     DataProcessor,\n\u001b[0;32m     29\u001b[0m     InputExample,\n\u001b[0;32m     30\u001b[0m     InputFeatures,\n\u001b[0;32m     31\u001b[0m     SingleSentenceClassificationProcessor,\n\u001b[0;32m     32\u001b[0m     SquadExample,\n\u001b[0;32m     33\u001b[0m     SquadFeatures,\n\u001b[0;32m     34\u001b[0m     SquadV1Processor,\n\u001b[0;32m     35\u001b[0m     SquadV2Processor,\n\u001b[0;32m     36\u001b[0m     glue_convert_examples_to_features,\n\u001b[0;32m     37\u001b[0m     glue_output_modes,\n\u001b[0;32m     38\u001b[0m     glue_processors,\n\u001b[0;32m     39\u001b[0m     glue_tasks_num_labels,\n\u001b[0;32m     40\u001b[0m     squad_convert_examples_to_features,\n\u001b[0;32m     41\u001b[0m     xnli_output_modes,\n\u001b[0;32m     42\u001b[0m     xnli_processors,\n\u001b[0;32m     43\u001b[0m     xnli_tasks_num_labels,\n\u001b[0;32m     44\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\data\\processors\\__init__.py:15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglue\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m glue_convert_examples_to_features, glue_output_modes, glue_processors, glue_tasks_num_labels\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msquad\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SquadExample, SquadFeatures, SquadV1Processor, SquadV2Processor, squad_convert_examples_to_features\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataProcessor, InputExample, InputFeatures, SingleSentenceClassificationProcessor\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\data\\processors\\glue.py:30\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataProcessor, InputExample, InputFeatures\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tf_available():\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     32\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     34\u001b[0m DEPRECATION_WARNING \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibrary. You can have a look at this example script for pointers: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[0m\n\u001b[0;32m     86\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     92\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     93\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     94\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     95\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\ashwinir\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import (\n",
    "    InformationRetrievalEvaluator,\n",
    "    SequentialEvaluator,\n",
    ")\n",
    "from sentence_transformers.util import cos_sim\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "model_id = \"BAAI/bge-base-en-v1.5\"  # Hugging Face model ID\n",
    "matryoshka_dimensions = [768, 512, 256, 128, 64] # Important: large to small\n",
    "\n",
    "# Load a model\n",
    "model = SentenceTransformer(\n",
    "    model_id, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# load test dataset\n",
    "test_dataset = load_dataset(\"json\", data_files=\"test_dataset.json\", split=\"train\")\n",
    "train_dataset = load_dataset(\"json\", data_files=\"train_dataset.json\", split=\"train\")\n",
    "corpus_dataset = concatenate_datasets([train_dataset, test_dataset])\n",
    "\n",
    "# Convert the datasets to dictionaries\n",
    "corpus = dict(\n",
    "    zip(corpus_dataset[\"id\"], corpus_dataset[\"positive\"])\n",
    ")  # Our corpus (cid => document)\n",
    "queries = dict(\n",
    "    zip(test_dataset[\"id\"], test_dataset[\"anchor\"])\n",
    ")  # Our queries (qid => question)\n",
    "\n",
    "# Create a mapping of relevant document (1 in our case) for each query\n",
    "relevant_docs = {}  # Query ID to relevant documents (qid => set([relevant_cids])\n",
    "for q_id in queries:\n",
    "    relevant_docs[q_id] = [q_id]\n",
    "\n",
    "\n",
    "matryoshka_evaluators = []\n",
    "# Iterate over the different dimensions\n",
    "for dim in matryoshka_dimensions:\n",
    "    ir_evaluator = InformationRetrievalEvaluator(\n",
    "        queries=queries,\n",
    "        corpus=corpus,\n",
    "        relevant_docs=relevant_docs,\n",
    "        name=f\"dim_{dim}\",\n",
    "        truncate_dim=dim,  # Truncate the embeddings to a certain dimension\n",
    "        score_functions={\"cosine\": cos_sim},\n",
    "    )\n",
    "    matryoshka_evaluators.append(ir_evaluator)\n",
    "\n",
    "# Create a sequential evaluator\n",
    "evaluator = SequentialEvaluator(matryoshka_evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "835ddda3-79ad-4342-aed4-d4b031a1549a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m(model)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# # COMMENT IN for full results\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# print(results)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Print the main score\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m matryoshka_dimensions:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluator' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = evaluator(model)\n",
    "\n",
    "# # COMMENT IN for full results\n",
    "# print(results)\n",
    "\n",
    "# Print the main score\n",
    "for dim in matryoshka_dimensions:\n",
    "    key = f\"dim_{dim}_cosine_ndcg@10\"\n",
    "    print\n",
    "    print(f\"{key}: {results[key]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
