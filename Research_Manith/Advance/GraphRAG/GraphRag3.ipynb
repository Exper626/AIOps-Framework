{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc5c2c-91ee-4ca4-9231-0c9995aa3be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import re\n",
    "\n",
    "# Step 1: Load dataset from Hugging Face\n",
    "dataset = load_dataset(\"ag_news\", split=\"train[:1%]\")  # Small subset for demo\n",
    "\n",
    "# Step 2: Tokenize and clean text\n",
    "def tokenize(text):\n",
    "    text = re.sub(r\"[^a-zA-Z ]\", \"\", text.lower())\n",
    "    return text.split()\n",
    "\n",
    "tokenized_corpus = [tokenize(example[\"text\"]) for example in dataset]\n",
    "\n",
    "# Step 3: Build vocabulary\n",
    "vocab = set(word for sentence in tokenized_corpus for word in sentence)\n",
    "word2idx = {word: i for i, word in enumerate(vocab)}\n",
    "idx2word = {i: word for word, i in word2idx.items()}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Step 4: Generate skip-gram pairs\n",
    "def generate_skip_grams(sentences, context_size):\n",
    "    pairs = []\n",
    "    for sentence in sentences:\n",
    "        for i, center in enumerate(sentence):\n",
    "            for j in range(max(0, i - context_size), min(len(sentence), i + context_size + 1)):\n",
    "                if i != j:\n",
    "                    pairs.append((center, sentence[j]))\n",
    "    return pairs\n",
    "\n",
    "context_size = 2\n",
    "pairs = generate_skip_grams(tokenized_corpus, context_size)\n",
    "pairs_idx = [(word2idx[c], word2idx[t]) for c, t in pairs]\n",
    "\n",
    "# Step 5: Define simple Word2Vec model\n",
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.linear = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed = self.embeddings(x)\n",
    "        return self.linear(embed)\n",
    "\n",
    "embedding_dim = 100\n",
    "model = Word2Vec(vocab_size, embedding_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Step 6: Training loop\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    random.shuffle(pairs_idx)\n",
    "    for center, context in pairs_idx:\n",
    "        center_tensor = torch.tensor([center])\n",
    "        context_tensor = torch.tensor([context])\n",
    "\n",
    "        output = model(center_tensor)\n",
    "        loss = criterion(output, context_tensor)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Step 7: Save embeddings\n",
    "torch.save(model.embeddings.state_dict(), \"custom_embeddings_hf.pt\")\n",
    "\n",
    "# Step 8: Retrieve embedding\n",
    "def get_embedding(word):\n",
    "    idx = word2idx.get(word)\n",
    "    if idx is not None:\n",
    "        with torch.no_grad():\n",
    "            return model.embeddings(torch.tensor(idx)).numpy()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "print(\"\\nSample embedding for 'news':\", get_embedding(\"news\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd6c9d6-6d77-4fb5-99fe-bb1184070c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Get embeddings matrix\n",
    "embedding_weights = model.embeddings.weight.detach().numpy()\n",
    "\n",
    "# Step 2: Select subset of words for clarity in visualization\n",
    "num_words_to_plot = 200  # limit to avoid clutter\n",
    "selected_indices = list(range(min(num_words_to_plot, vocab_size)))\n",
    "selected_embeddings = embedding_weights[selected_indices]\n",
    "selected_labels = [idx2word[i] for i in selected_indices]\n",
    "\n",
    "# Step 3: Dimensionality reduction with t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "reduced = tsne.fit_transform(selected_embeddings)\n",
    "\n",
    "# Step 4: Plot\n",
    "plt.figure(figsize=(14, 10))\n",
    "for i, label in enumerate(selected_labels):\n",
    "    x, y = reduced[i]\n",
    "    plt.scatter(x, y, marker='o', color='blue')\n",
    "    plt.text(x + 0.1, y + 0.1, label, fontsize=9)\n",
    "\n",
    "plt.title(\"Word Embeddings Visualization (t-SNE)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f04020-98ea-487f-8648-2d9d68909f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# Define LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Define prompt template\n",
    "template = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use two sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Setup RAG pipeline\n",
    "rag_chain = (\n",
    "    {\"context\": retriever,  \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67939088-5a79-46e2-84d7-ed7c9c30d869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
