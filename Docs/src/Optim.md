# Other Optimizations


#### 1. Proximal Policy Optimization (PPO) 
- Fine-tune the LLM based on reward signals 




#### 2. Mixture of Experts (MoE)
- Instead of one big model doing everything, route each input to the best set of experts dynamical




#### 3. Group Relative Policy Optimization (GRPO) 
-  Extends the Policy Optimization framework to improve how policies are learned in environments where there are multiple agents or multiple strategies that need to be optimized together.




#### 4. Knowledge Distiliation
- Transfer knowledge from a larger, more complex model (often referred to as the teacher model) to a smaller, more efficient model (the student model). 



## LLM Inference platforms

#### 1. Runpod
#### 2. AWS
#### 3. Lambda Labs


